{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "print('Current conda environment:', os.environ['CONDA_DEFAULT_ENV'])\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"false\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data from REINVENT, CReM, SAFE, and COATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "\n",
    "from crem.crem import grow_mol, mutate_mol\n",
    "crem_db = '../crem_db/crem_db2.5.db'\n",
    "\n",
    "import mols2grid\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdFingerprintGenerator, CanonSmiles, Draw, MolFromSmiles, PandasTools\n",
    "from rdkit.Chem.rdmolops import RDKFingerprint\n",
    "from rdkit import DataStructs\n",
    "from rdkit.DataStructs.cDataStructs import BulkTanimotoSimilarity\n",
    "import useful_rdkit_utils as uru\n",
    "\n",
    "import safe as sf\n",
    "import datamol as dm\n",
    "\n",
    "import mols2grid\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "\n",
    "from coati.generative.coati_purifications import embed_smiles\n",
    "from coati.models.io.coati import load_e3gnn_smiles_clip_e2e\n",
    "from coati.models.simple_coati2.io import load_coati2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = 'Nc1cc(c[nH]c1=O)C(F)(F)F'\n",
    "initial_mol = MolFromSmiles(initial)\n",
    "initial_mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto_similarity(smi_1, smi_2, use_counts=True):\n",
    "    fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048,countSimulation=True)\n",
    "    mol_1 = Chem.MolFromSmiles(smi_1)\n",
    "    mol_2 = Chem.MolFromSmiles(smi_2)\n",
    "    if use_counts:\n",
    "        fp_1 = rdFingerprintGenerator.GetCountFPs([mol_1])[0]\n",
    "        fp_2 = rdFingerprintGenerator.GetCountFPs([mol_2])[0]\n",
    "    else:\n",
    "        fp_1 = rdFingerprintGenerator.GetFPs([mol_1])[0]\n",
    "        fp_2 = rdFingerprintGenerator.GetFPs([mol_2])[0]\n",
    "    return DataStructs.TanimotoSimilarity(fp_1, fp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_odd_rings(df):\n",
    "    ring_system_lookup = uru.RingSystemLookup.default()\n",
    "    df['ring_systems'] = df.SMILES.apply(ring_system_lookup.process_smiles)\n",
    "    df[['min_ring','min_freq']] = df.ring_systems.apply(uru.get_min_ring_frequency).to_list()\n",
    "    df = df.query('min_freq > 100').copy()\n",
    "    return df.iloc[:, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating analogs w/ REINVENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "\n",
    "arg1 = f'--input_frag'\n",
    "subprocess.run(['python3', 'generate_analogs.py', arg1, initial],\n",
    "               stdout=subprocess.DEVNULL,\n",
    "               stderr=subprocess.STDOUT)\n",
    "        \n",
    "# Change directory back to that of the current notebook\n",
    "%cd experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/reinvent_dataframe.csv')\n",
    "\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=500)\n",
    "df['Model'] = 'reinvent'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating analogs w/ CReM\n",
    "Here we use the mutate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = []\n",
    "mutate_list = list(mutate_mol(initial_mol, db_name=crem_db, return_mol=False))\n",
    "\n",
    "for idx, analog in enumerate(mutate_list):\n",
    "    out_list.append([analog, initial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(out_list, columns=[\"SMILES\",\"Input_SMILES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crem_smiles = temp_df['SMILES'].values\n",
    "\n",
    "sim_to_initial = [tanimoto_similarity(smile, initial) for smile in crem_smiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['Tanimoto'] = sim_to_initial\n",
    "\n",
    "temp_df = remove_odd_rings(temp_df)\n",
    "\n",
    "temp_df['Model'] = 'crem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating analogs w/ COATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1, tokenizer1 = load_e3gnn_smiles_clip_e2e(\n",
    "    freeze=True,\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    doc_url=\"s3://terray-public/models/barlow_closed.pkl\"\n",
    ")\n",
    "\n",
    "encoder2, tokenizer2 = load_coati2(\n",
    "    freeze=True,\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    doc_url=\"s3://terray-public/models/coati2_chiral_03-08-24.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mol(smiles, coati_version=1, num_variations=100, noise_scale=0.15):\n",
    "\n",
    "    # Embed the SMILES string\n",
    "    smiles = CanonSmiles(smiles)\n",
    "\n",
    "    if coati_version == 1:\n",
    "        vector = embed_smiles(smiles, encoder1, tokenizer1)\n",
    "    elif coati_version == 2:\n",
    "        vector = embed_smiles(smiles, encoder2, tokenizer2)\n",
    "\n",
    "    # Noise is added as an isotropic Gaussian with std=noise_scale\n",
    "    if coati_version == 1:\n",
    "        nearby_smiles = encoder1.hclip_to_2d_batch(\n",
    "            h_clip=vector.unsqueeze(0).repeat(num_variations, 1),\n",
    "            tokenizer=tokenizer1,\n",
    "            noise_scale=noise_scale\n",
    "        )\n",
    "    elif coati_version == 2:\n",
    "        nearby_smiles = encoder2.hcoati_to_2d_batch(\n",
    "            h_coati=vector.unsqueeze(0).repeat(num_variations, 1),\n",
    "            tokenizer=tokenizer2,\n",
    "            noise_scale=noise_scale,\n",
    "        )\n",
    "\n",
    "    # Retrieve canonical SMILES of generated analogs\n",
    "    unique_valid_smiles = list(set([CanonSmiles(smi) for smi in nearby_smiles if MolFromSmiles(smi)]))\n",
    "\n",
    "    # Store true if original molecule is in the set of generated analogs\n",
    "    had_orig = smiles in unique_valid_smiles\n",
    "\n",
    "    unique_valid_smiles = list(set([smiles] + unique_valid_smiles))\n",
    "\n",
    "    # Generate molecular fingerprints\n",
    "    fp = RDKFingerprint(MolFromSmiles(smiles), minPath=1, maxPath=7, fpSize=2048)\n",
    "    fps = [RDKFingerprint(MolFromSmiles(x), minPath=1, maxPath=7, fpSize=2048) for x in unique_valid_smiles]\n",
    "\n",
    "    # Compute tanimoto similarities between distributions and store as list of strings\n",
    "    sim = BulkTanimotoSimilarity(fp, fps)\n",
    "    sim_str = [str(round(x, 2)) for x in sim]\n",
    "\n",
    "    unique_valid_smiles, sim_str = zip(*sorted(zip(unique_valid_smiles, sim_str), key=lambda x:x[1], reverse=True))\n",
    "\n",
    "    if not had_orig:\n",
    "        unique_valid_smiles, sim_str = zip(*[[i, f\"{j} (Added)\"] if i==smiles else [i, j] for i, j in zip(unique_valid_smiles, sim_str)])\n",
    "\n",
    "    # Output for molecule generation\n",
    "    print (f\"Attempted {num_variations} COATI{coati_version} generations with a noise scale of {noise_scale} and generated {len(unique_valid_smiles)} unique structures.\")\n",
    "    \n",
    "    # Display molecules and tanimoto similarity to initial fragment\n",
    "    # display(Draw.MolsToGridImage([MolFromSmiles(s) for s in unique_valid_smiles], molsPerRow=5, subImgSize=(200, 200), maxMols=100, legends=sim_str))\n",
    "    \n",
    "    return unique_valid_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coati_smiles = gen_mol(initial, coati_version = 2, num_variations = 1000, noise_scale = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame()\n",
    "temp_df['SMILES'] = coati_smiles\n",
    "temp_df['Input_SMILES'] = initial\n",
    "\n",
    "len(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_to_initial = [tanimoto_similarity(smile, initial) for smile in coati_smiles]\n",
    "\n",
    "temp_df['Tanimoto'] = sim_to_initial\n",
    "\n",
    "temp_df = remove_odd_rings(temp_df)\n",
    "\n",
    "temp_df['Model'] = 'coati'\n",
    "\n",
    "len(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating analogs w/ SAFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designer = sf.SAFEDesign.load_default(verbose=True)\n",
    "\n",
    "designer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_smiles = designer.super_structure(\n",
    "    core=initial,\n",
    "    n_samples_per_trial=200,\n",
    "    n_trials=1,\n",
    "    sanitize=True,\n",
    "    do_not_fragment_further=False,\n",
    "    attachment_point_depth=3,\n",
    ")\n",
    "\n",
    "generated_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame()\n",
    "temp_df['SMILES'] = generated_smiles\n",
    "temp_df['Input_SMILES'] = initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_to_initial = [tanimoto_similarity(smile, initial) for smile in generated_smiles]\n",
    "\n",
    "temp_df['Tanimoto'] = sim_to_initial\n",
    "\n",
    "temp_df = remove_odd_rings(temp_df)\n",
    "\n",
    "temp_df['Model'] = 'safe'\n",
    "\n",
    "len(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the models in chemical space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = df['SMILES'].values\n",
    "mols = [MolFromSmiles(smile) for smile in smiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpgen = AllChem.GetMorganGenerator()\n",
    "\n",
    "fingerprints = [fpgen.GetFingerprint(mol).ToList() for mol in mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fingerprints'] = fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fingerprints\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3, random_state=0)\n",
    "pca_fps = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1, var2, var3 = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PC1'], df['PC2'], df['PC3'] = pca_fps.T[0], pca_fps.T[1], pca_fps.T[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.pairplot(plot_df,\n",
    "                 hue='Model',\n",
    "                 vars=['PC1', 'PC2', 'PC3'],\n",
    "                 palette='colorblind',\n",
    "                 aspect=2,\n",
    "                 plot_kws=dict(s=10))\n",
    "\n",
    "f.fig.suptitle('Pairwise Principle Component Plots', fontsize=18, y=1.04);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 100\n",
    "\n",
    "pca_model = PCA(n_components=5, random_state=0)\n",
    "tsne_model = TSNE(n_components=2, random_state=0, perplexity=p, n_iter=5000)\n",
    "tsne_fps = tsne_model.fit_transform(pca_model.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TSNE1'], df['TSNE2'] = tsne_fps.T[0], tsne_fps.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.pairplot(df,\n",
    "                 hue='Model',\n",
    "                 vars=['TSNE1', 'TSNE2'],\n",
    "                 palette='colorblind',\n",
    "                 aspect=2,\n",
    "                 plot_kws=dict(s=10))\n",
    "\n",
    "title = f'Pairwise t-SNE plot w/ perplexity $p={p}$'\n",
    "\n",
    "f.fig.suptitle(title, fontsize=18, y=1.04);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Davies Boulin index to evaluate clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_dvs = davies_bouldin_score(tsne_fps, df['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Davies-Bouldin Index for t-SNE: {tsne_dvs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set UMAP parameters\n",
    "num_neighbors = 100 # similar to perplexity in t-SNE\n",
    "reduced_dim = 2\n",
    "rs = 0 # random state\n",
    "\n",
    "# Apply UMAP\n",
    "umap_model = umap.UMAP(n_components=reduced_dim, n_neighbors=num_neighbors, random_state=rs, init=\"pca\")\n",
    "umap_projection = umap_model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UMAP1'], df['UMAP2'] = umap_projection.T[0], umap_projection.T[1]\n",
    "\n",
    "f = sns.pairplot(df,\n",
    "                    hue='Model',\n",
    "                    vars=['UMAP1', 'UMAP2'],\n",
    "                    palette='colorblind',\n",
    "                    aspect=2,\n",
    "                    plot_kws=dict(s=10))\n",
    "\n",
    "title = f'Pairwise UMAP plot w/ neighbors $n={num_neighbors}$'\n",
    "\n",
    "\n",
    "f.fig.suptitle(title, fontsize=18, y=1.04);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.scatterplot(data=df, x='TSNE1', y='TSNE2', hue='Model', palette='colorblind', s=20)\n",
    "\n",
    "title = f't-SNE plot w/ perplexity $p={p}$'\n",
    "\n",
    "plt.title(title, fontsize=18);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.scatterplot(data=df, x='UMAP1', y='UMAP2', hue='Model', palette='colorblind', s=20)\n",
    "\n",
    "title = f'UMAP plot w/ neighbors $n={num_neighbors}$'\n",
    "\n",
    "subtext = f'Random state: {rs}' \n",
    "\n",
    "plt.title(title, fontsize=18);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Davies Bouldin score for UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_dvs = davies_bouldin_score(umap_projection, df['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Davies-Bouldin Index for UMAP: {umap_dvs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use KNN and SVM for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a train test split of the df\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.1, random_state=42, stratify=df['Model'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train size: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert each fingerprint to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fg = X_train['Fingerprints'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fg = np.array([np.array(x) for x in X_train_fg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fg = X_test['Fingerprints'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fg = np.array([np.array(x) for x in X_test_fg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dictionary of models\n",
    "\n",
    "model_dict = {'reinvent': 0, 'crem': 1, 'coati': 2, 'safe': 3}\n",
    "\n",
    "#now relabel the models\n",
    "\n",
    "y_train = X_train['Model'].map(model_dict)\n",
    "y_test = X_test['Model'].map(model_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run KNN on the training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a simple classifier KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "UMAP_train = X_train[['UMAP1', 'UMAP2']].values\n",
    "KNN.fit(UMAP_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KNN.predict(X_test[['UMAP1', 'UMAP2']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = LinearSVC()\n",
    "SVC.fit(UMAP_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVC.predict(X_test[['UMAP1', 'UMAP2']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Tanimoto similarity of each model to the Initial Fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = [tanimoto_similarity(smile, initial) for smile in df['SMILES'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tanimoto'] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df, x='Tanimoto', hue='Model', bins=20, kde=True, palette='colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=df, x='Model', y='Tanimoto', palette='colorblind')\n",
    "\n",
    "plt.title('Tanimoto Similarity to Initial Fragment', fontsize=18);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Tanimoto Similarity to the Lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 'N[C@H]1CCN(Cc2cccc(c2)c3ccc4c(=O)[nH]ccc4c3)C1'\n",
    "lead_mol = MolFromSmiles(lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_sim = [tanimoto_similarity(smile, lead) for smile in df['SMILES'].values]\n",
    "\n",
    "df['Tanimoto_Lead'] = lead_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=df, x='Model', y='Tanimoto_Lead', palette='colorblind')\n",
    "\n",
    "plt.title('Tanimoto Similarity to Lead Compound', fontsize=18);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df, x='Tanimoto_Lead', hue='Model', bins=20, kde=True, palette='colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can approximate the number of unique molecules in each distribution with Vendi Sore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto_similarity_matrix(fps):\n",
    "    sim_matrix = np.zeros((len(fps), len(fps)))\n",
    "    for i in range(len(fps)):\n",
    "        for j in range(len(fps)):\n",
    "            sim_matrix[i, j] = DataStructs.TanimotoSimilarity(fps[i], fps[j])\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity_matrix(sim_matrix, title):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(sim_matrix, cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vendi_score import vendi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinvent_fps = [fpgen.GetFingerprint(Chem.MolFromSmiles(smiles)) for smiles in df.query('Model == \"reinvent\"')['SMILES'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinvent_sim_matrix = tanimoto_similarity_matrix(reinvent_fps)\n",
    "vendi.score_K(reinvent_sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crem_fps = [fpgen.GetFingerprint(Chem.MolFromSmiles(smiles)) for smiles in df.query('Model == \"crem\"')['SMILES'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crem_sim_matrix = tanimoto_similarity_matrix(crem_fps)\n",
    "vendi.score_K(crem_sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coati_fps = [fpgen.GetFingerprint(Chem.MolFromSmiles(smiles)) for smiles in df.query('Model == \"coati\"')['SMILES'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coati_sim_matrix = tanimoto_similarity_matrix(coati_fps)\n",
    "vendi.score_K(coati_sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_fps = [fpgen.GetFingerprint(Chem.MolFromSmiles(smiles)) for smiles in df.query('Model == \"safe\"')['SMILES'].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_sim_matrix = tanimoto_similarity_matrix(safe_fps)\n",
    "vendi.score_K(safe_sim_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinvent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
