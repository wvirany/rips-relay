{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piggybacking Experiment\n",
    "\n",
    "This notebook implements the hit-to-lead optimization algorithm (\"piggybacking\") for lead rediscovery using the `fragment_lead_pairs.csv` data as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some miscellaneous notes:\n",
    "* In this notebook, we use the `frag_idx` parameter to refer to the index (1-indexed, not 0-indexed) of the fragment lead pair according to `fragment_lead_pairs.csv`. In the csv, there is a column \"Table Entry\" that enumerates the pairs but rolls over at each year. For instance, one of the rows in the fragment_lead_pairs.csv is: `2021,1,COc1ccc(cc1)C2CC(=O)NCCS2,COc1ccc(NC(=O)C[C@@H]2SCCNC2=O)cc1` which we refer to in this notebook as having `frag_idx = 16` (because it is the 16th fragment from the top in the table)\n",
    "* Currently for REINVENT4, we are prompting each of the 6 priors (excluding pubchem) to generate 20 molecules each, then combining all of the outputs. To change this, edit the `num_smiles` value (line 35) in the toml files (which can be found in the `mol2mol_prior_tomls` folder)\n",
    "* `pifp_counts` is a bit of a misnomer; it is not the number of protein interactions, but rather the Tanimoto similarity of the analog's protein interaction fingerprint to the protein interaction fingerprint of the lead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup\n",
    "These are just the basic imports and packages that we use for this notebook. Note that in the first code block you have to set the path to the OpenEye license to the correct path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current conda environment: reinvent\n",
      "/home/fts_g_ucla_edu/Projects/rips-relay_copy/experiments\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "print('Current conda environment:', os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "os.environ[\"PATH\"] += \":/usr/local/openeye/bin\"\n",
    "# set this path to the correct path\n",
    "os.environ[\"OE_LICENSE\"] = \"/home/fts_g_ucla_edu/Projects/oe_license.txt\"\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"false\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n",
      "2024-08-21 16:27:13.475364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-21 16:27:13.498735: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-21 16:27:13.505701: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-21 16:27:13.522896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-21 16:27:14.578633: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import mols2grid\n",
    "import useful_rdkit_utils as uru\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "import MDAnalysis as mda\n",
    "import prolif as plf\n",
    "from rdkit.Chem.rdFMCS import FindMCS\n",
    "\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crem.crem import grow_mol, mutate_mol\n",
    "crem_db = '../crem_db/crem_db2.5.db'\n",
    "\n",
    "import mols2grid\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdFingerprintGenerator, CanonSmiles, Draw, MolFromSmiles, PandasTools\n",
    "from rdkit.Chem.rdmolops import RDKFingerprint\n",
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem.rdFMCS import FindMCS\n",
    "from rdkit.DataStructs.cDataStructs import BulkTanimotoSimilarity\n",
    "import useful_rdkit_utils as uru\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import DataStructs\n",
    "\n",
    "import prolif as plf\n",
    "\n",
    "import safe as sf\n",
    "import datamol as dm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import itertools \n",
    "from coati.generative.coati_purifications import embed_smiles\n",
    "from coati.models.io.coati import load_e3gnn_smiles_clip_e2e\n",
    "from coati.models.simple_coati2.io import load_coati2\n",
    "\n",
    "from molscore import MolScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data and defining some useful reference constants\n",
    "Here we read in the `data/fragment_lead_pairs.csv` data and the csv that converts the index of the fragment (in the fragment lead pairs csv) to the name of the pdb file (`data/pdb_name_map.csv`). We also set up some basic constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Table_Entry</th>\n",
       "      <th>Fragment</th>\n",
       "      <th>Lead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Nc1cc(c[nH]c1=O)C(F)(F)F</td>\n",
       "      <td>N[C@H]1CCN(Cc2cccc(c2)c3ccc4c(=O)[nH]ccc4c3)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>CN1C[C@@H](O)[C@H](C1=O)c2ccc(C)cc2</td>\n",
       "      <td>COc1ccc(CN2C[C@H](O)[C@](CCC(C)C)(C2=O)c3ccc(c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>Fc1cncc(c1)N2C(=O)N[C@@H](Cc3ccccc3)C2=O</td>\n",
       "      <td>Clc1ccccc1C2CC3(C2)NC(=O)N(C3=O)c4cncc5ccccc45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>c1ccc(cc1)c2ccccc2c3nnn[nH]3</td>\n",
       "      <td>Cc1ccc(cc1)c2cccc(c2c3nnn[nH]3)S(=O)(=O)N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>CN(C)C(=O)C(N)Cc1ccc(F)cc1</td>\n",
       "      <td>Clc1ccc(cc1)[C@H]2CN[C@H](C2)C(=O)N3CCN(CC3)c4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Table_Entry                                  Fragment  \\\n",
       "0  2022            1                  Nc1cc(c[nH]c1=O)C(F)(F)F   \n",
       "1  2022            2       CN1C[C@@H](O)[C@H](C1=O)c2ccc(C)cc2   \n",
       "2  2022            3  Fc1cncc(c1)N2C(=O)N[C@@H](Cc3ccccc3)C2=O   \n",
       "3  2022            4              c1ccc(cc1)c2ccccc2c3nnn[nH]3   \n",
       "4  2022            5                CN(C)C(=O)C(N)Cc1ccc(F)cc1   \n",
       "\n",
       "                                                Lead  \n",
       "0     N[C@H]1CCN(Cc2cccc(c2)c3ccc4c(=O)[nH]ccc4c3)C1  \n",
       "1  COc1ccc(CN2C[C@H](O)[C@](CCC(C)C)(C2=O)c3ccc(c...  \n",
       "2     Clc1ccccc1C2CC3(C2)NC(=O)N(C3=O)c4cncc5ccccc45  \n",
       "3          Cc1ccc(cc1)c2cccc(c2c3nnn[nH]3)S(=O)(=O)N  \n",
       "4  Clc1ccc(cc1)[C@H]2CN[C@H](C2)C(=O)N3CCN(CC3)c4...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fragment_lead_pairs = pd.read_csv('data/fragment_lead_pairs.csv')\n",
    "\n",
    "fragment_lead_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global constants\n",
    "models = ['reinvent', 'crem', 'safe', 'coati']\n",
    "metrics = ['tanimoto_to_lead', 'docking_score', 'pifp_count', 'NNpredict_tani_to_lead']\n",
    "pdb_names = pd.read_csv(\"data/pdb_name_map.csv\")\n",
    "mol2mol_priors = ['sim', \n",
    "                             'medsim', \n",
    "                             'highsim', \n",
    "                             'scaffold', \n",
    "                             'genscaffold', \n",
    "                             'mmp']\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "This section just contains some helper functions to use when computing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeats(df, inchi_names):\n",
    "    \"\"\"\n",
    "    Removes rows with repeated 'inchi' and 'Model' values.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame with columns 'inchi' and 'Model'\n",
    "    inchi_names (list): List of inchi names to check for repeats\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with repeats removed\n",
    "    \"\"\"\n",
    "\n",
    "    # # TODO: remove this block of code\n",
    "    # df.to_csv('data/garbage/remove_repeats_df.csv')\n",
    "    # if 'Model' not in df.columns:\n",
    "    #     raise KeyError(\"The 'Model' column is missing from the DataFrame!\")\n",
    "\n",
    "    # Iterate over each inchi name in inchi_names\n",
    "    for inchi_name in inchi_names:\n",
    "        # Get the subset of the DataFrame for the current inchi_name\n",
    "        df_inchi = df[df['inchi'] == inchi_name]\n",
    "        \n",
    "        duplicates = df_inchi[df_inchi.duplicated(subset=['inchi'], keep='first')]\n",
    "        # TODO: replace the above with below (below is original, above it possible fix)\n",
    "        # # Find duplicates based on 'inchi' and 'Model' columns\n",
    "        # duplicates = df_inchi[df_inchi.duplicated(subset=['inchi', 'Model'], keep='first')]\n",
    "        \n",
    "        # Drop the duplicate rows from the original DataFrame\n",
    "        df = df.drop(duplicates.index)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_sdf_files(output_sdf, lead_sdf, analogs_sdf):\n",
    "    # helper for pifp_distance_to_lead\n",
    "    with open(output_sdf, 'w') as outfile:\n",
    "        with open(lead_sdf, 'r') as infile:\n",
    "            first_line = infile.readline().strip()\n",
    "            outfile.write(\"MOL9999\\n\")  # Replace first line with \"MOL9999\"\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "        with open(analogs_sdf, 'r') as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_tanimoto_similarity(row1, row2):\n",
    "    # Compute the bitwise AND and OR\n",
    "    intersection = np.sum(np.logical_and(row1, row2))\n",
    "    union = np.sum(np.logical_or(row1, row2))\n",
    "    # Calculate Tanimoto similarity\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_directory(directory_path):\n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(directory_path):\n",
    "        # Iterate over all the files and subdirectories in the directory\n",
    "        for filename in os.listdir(directory_path):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                # Remove files\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                # Remove directories\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    else:\n",
    "        print(f'Directory {directory_path} does not exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_file(directory, filename):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    print(f\"Please upload the file '{filename}' to the folder '{directory}'.\")\n",
    "\n",
    "    # Pause the script until the file is found\n",
    "    while not os.path.isfile(file_path):\n",
    "        print(f\"Waiting for '{filename}' to be uploaded...\")\n",
    "        time.sleep(5)  # Wait for 5 seconds before checking again\n",
    "\n",
    "    print(f\"File '{filename}' found.\")\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric functions\n",
    "The functions in this section define the metrics that we use to evaluate the quality of the molecules. Some of these functions depend on external files/directories (beyond the ones passed in as parameters). They are listed below:\n",
    "\n",
    "pifp_distance_to_lead:\n",
    "* `data/docking/pairs`\n",
    "* `placeholder_concat.sdf`\n",
    "\n",
    "NNpredict_tani_to_lead:\n",
    "* `data/molscore_dummy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto_similarity(smi_1, smi_2, use_counts=True):\n",
    "    # Note this refers to molecular tanimoto similarity\n",
    "    fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048,countSimulation=True)\n",
    "    mol_1 = Chem.MolFromSmiles(smi_1)\n",
    "    mol_2 = Chem.MolFromSmiles(smi_2)\n",
    "    if use_counts:\n",
    "        fp_1 = rdFingerprintGenerator.GetCountFPs([mol_1])[0]\n",
    "        fp_2 = rdFingerprintGenerator.GetCountFPs([mol_2])[0]\n",
    "    else:\n",
    "        fp_1 = rdFingerprintGenerator.GetFPs([mol_1])[0]\n",
    "        fp_2 = rdFingerprintGenerator.GetFPs([mol_2])[0]\n",
    "    return DataStructs.TanimotoSimilarity(fp_1, fp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pifp_distance_to_lead(path_to_analog_sdf, frag_idx, pdb_type):\n",
    "\n",
    "    # takes in path to analog sdfs and returns a list of pifp tani similarities\n",
    "\n",
    "    PDB_FILEPATH = f\"data/docking/pairs/{frag_idx}_{pdb_type}.pdb\"\n",
    "\n",
    "    fp = plf.Fingerprint()\n",
    "\n",
    "    mol = Chem.MolFromPDBFile(PDB_FILEPATH, removeHs=False)\n",
    "    prot = plf.Molecule(mol)\n",
    "\n",
    "    # concat analog sdf with lead sdf\n",
    "    path_to_lead_sdf = f\"data/docking/pairs/{frag_idx}_lead_smi_to_{pdb_type}_pdb.sdf\"\n",
    "    concat_sdf_path = f\"placeholder_concat.sdf\"\n",
    "    concatenate_sdf_files(output_sdf=concat_sdf_path, lead_sdf=path_to_lead_sdf, analogs_sdf=path_to_analog_sdf)\n",
    "\n",
    "    # get pifp\n",
    "    suppl = plf.sdf_supplier(concat_sdf_path)\n",
    "    fp.run_from_iterable(suppl,prot,progress=True)\n",
    "    df = fp.to_dataframe()\n",
    "\n",
    "    numpy_df = (df.astype('int')).to_numpy()\n",
    "\n",
    "    num_rows = numpy_df.shape[0]\n",
    "    first_row = numpy_df[0]\n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(1, num_rows):\n",
    "        similarity = general_tanimoto_similarity(first_row, numpy_df[i])\n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docking_score(path_to_analog_smi, output_oeb_path, path_to_oedu, output_sdf_path, saved_sdf_path=None):\n",
    "    \n",
    "    # run through omega\n",
    "    command = f\"/usr/local/openeye/bin/omega2 -in {path_to_analog_smi} -out {output_oeb_path} -strictstereo false\"\n",
    "    os.system(command)\n",
    "\n",
    "    # run through hybrid\n",
    "    command = f\"/usr/local/openeye/bin/hybrid -receptor {path_to_oedu} -dbase {output_oeb_path} -out {output_sdf_path}\"\n",
    "    os.system(command)\n",
    "    \n",
    "    # read in output sdf from hybrid\n",
    "    docked_df = PandasTools.LoadSDF(output_sdf_path)\n",
    "\n",
    "    # save docked_df as csv if desired\n",
    "    if saved_sdf_path != None:\n",
    "        PandasTools.LoadSDF(output_sdf_path).to_csv(saved_sdf_path, index=False)\n",
    "\n",
    "    # return the docking scores\n",
    "    return docked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNpredict_tani_to_lead(df, path_to_scaler, path_to_model, curr_iter):\n",
    "\n",
    "    columns_to_keep = ['SMILES', 'HYBRID Chemgauss4 score', 'min_freq']\n",
    "    df = df.loc[:, columns_to_keep]\n",
    "\n",
    "    smiles = df['SMILES'].to_list()\n",
    "\n",
    "    ms = MolScore(model_name='mol2mol', task_config='molscore/feature_selection.json')\n",
    "    scores = ms.score(smiles)\n",
    "\n",
    "    # Once finished\n",
    "    metrics = ms.compute_metrics(\n",
    "        endpoints=None, # Optional list: by default will use the running final score/reward value\n",
    "        thresholds=None,  # Optional list: if specified will calculate the yield of molecules above that threshold \n",
    "        # chemistry_filters_basic=False,  # Optional, bool: Additionally re-calculate metrics after filtering out unreasonable chemistry\n",
    "        budget=10000,  # Optional, int: Calculate metrics only with molecules within this budget\n",
    "        n_jobs=1,  # Optional, int: Multiprocessing\n",
    "        benchmark=None,  # Optional, str: Name of benchmark, this may specify additional metrics to compute\n",
    "    )\n",
    "\n",
    "    directory_path = 'data/molscore_dummy'  \n",
    "    # List all entries in the directory\n",
    "    entries = os.listdir(directory_path)\n",
    "    # Filter out only the directories\n",
    "    folders = [entry for entry in entries if os.path.isdir(os.path.join(directory_path, entry))]\n",
    "    # Assuming there is only one folder, add its name to the path\n",
    "    file_path = f\"{directory_path}/{folders[0]}/iterations/000001_scores.csv\"\n",
    "    # Read in the molscore output\n",
    "    df2 = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "    # Clear out the directory\n",
    "    clear_directory(directory_path=directory_path)\n",
    "    \n",
    "    # Rename columns\n",
    "    column_names = {\n",
    "    'desc_Bertz' : 'Synthetic Complexity',\n",
    "    'interaction weight ratio' : 'Avg Interaction Strength',\n",
    "    'Weighted IFP Similarity' : 'Weighted Interaction Similarity',\n",
    "    'RAScore_pred_proba' : 'Synthetic Accessibility',\n",
    "    'desc_NumHeteroatoms' : '# Heteroatoms',\n",
    "    'desc_HeavyAtomMolWt': \"Heavy Atom MolWt\", \n",
    "    'desc_NumHAcceptors': '# HAcceptors', \n",
    "    'desc_NumHDonors':\"#HDonors\",\n",
    "    'desc_NumRotatableBonds': '# Rotatable Bonds',\n",
    "    'desc_NumAromaticRings': '# Aromatic Rings', \n",
    "    'desc_NumAliphaticRings': 'Number Aliphatic Rings', \n",
    "    'desc_RingCount': 'Ring Count',\n",
    "    'desc_TPSA': 'TPSA', \n",
    "    'desc_FormalCharge': 'Formal Charge',\n",
    "    'desc_CLogP': 'CLogP',\n",
    "    'desc_MolWt': 'MolWt', \n",
    "    'desc_HeavyAtomCount': 'Heavy Atom Count',\n",
    "    'desc_MaxConsecutiveRotatableBonds': 'Max Consecutive Rotatable Bonds',\n",
    "    'tanimoto_Sim': 'Tanimoto Sim',\n",
    "    'dice_Sim': 'Dice Sim',\n",
    "    'desc_FlourineCount':'Fluorine Count',\n",
    "    'desc_QED': 'QED',\n",
    "    'smiles': 'SMILES'\n",
    "    }\n",
    "    df2.rename(columns=column_names, inplace=True)\n",
    "    \n",
    "    # Define the columns to keep (i.e. to use for inference)\n",
    "    columns_to_keep = ['SMILES', 'QED', 'CLogP', 'MolWt', 'Heavy Atom Count', 'Heavy Atom MolWt', \n",
    "                       '# HAcceptors', '#HDonors', '# Heteroatoms', '# Rotatable Bonds', \n",
    "                       '# Aromatic Rings', 'Number Aliphatic Rings', 'Ring Count', 'TPSA', \n",
    "                       'Formal Charge', 'Synthetic Complexity', 'Max Consecutive Rotatable Bonds', \n",
    "                       'Fluorine Count', 'Synthetic Accessibility']\n",
    "    df2 = df2.loc[:, columns_to_keep]\n",
    "\n",
    "    # Combine molscore data with existing data\n",
    "    data = pd.merge(df2, df, on='SMILES')\n",
    "    data = data.drop('SMILES', axis=1)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Load the scaler\n",
    "    scaler = joblib.load(path_to_scaler)\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model(path_to_model)\n",
    "\n",
    "    # Apply the same scaling to the new data\n",
    "    new_features = data.values\n",
    "    new_features_scaled = scaler.transform(new_features)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(new_features_scaled)\n",
    "\n",
    "    return predictions['predicted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piggybacking function definition\n",
    "This section contains code for the actual hit-to-lead optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the score weighting/aggregation function\n",
    "# This takes in a weight array, a metric (index in metrics array), and a score and returns the weighted/adjusted score\n",
    "# This is a very rudimentary \n",
    "def weighted_score_contribution(weights, metric_type, score):\n",
    "    # molecular tanimoto similarity to lead\n",
    "    if metric_type == 0:\n",
    "        # higher is already better so just return itself\n",
    "        return float(weights[metric_type] * score)\n",
    "    # docking score\n",
    "    elif metric_type == 1:\n",
    "        # makes it so that higher (more positive) is better\n",
    "        return float(weights[metric_type] * (-1) * score)\n",
    "    # pifp counts\n",
    "    elif metric_type == 2:\n",
    "        # higher is already better so just return itself\n",
    "        return float(weights[metric_type] * score)\n",
    "    # neural net predicted score\n",
    "    elif metric_type == 3:\n",
    "        # NN should be predicting tanimoto sim to lead so just return itself\n",
    "        return float(weights[metric_type] * score)\n",
    "    # nonsense\n",
    "    else:\n",
    "        raise ValueError('[weighted_score_contribution]: invalid value for metric_type.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note about the piggybacking parameters:\n",
    "* `frag_lead_idx`: index of the fragment lead pair you would like to run the experiment on. Note that we may not have pdb/oedu files for all of the pairs (check `data/pdb_name_map.csv` to see if we were able to find the pdb files and generate oedu files).\n",
    "* `pdb_type`: in the published table of fragment lead pairs, there are two types of pdb files: those associated with the fragment, and those associated with the lead. Use `pdb_type` to specify if you are using the fragment pdb (`pdb_type = 'frag'`) or the lead pdb (`pdb_type = 'lead'`)\n",
    "* `model_idx`: index of the generative model to use (see the `models` array defined in the \"Reading in data...\" section). We have only implemented functionality for REINVENT4 and CReM.\n",
    "* `weights`: how to weight each of the four metrics according to the `metrics` array defined the \"Reading in data...\" section. These weights should add up to 1 and compute a weighted average of the four metrics to compute the final score for each molecule.\n",
    "* `k`: choose the top-`k` analogs at each iteration.\n",
    "* `max_iterations`: maximum number of iterations to run before quitting.\n",
    "* `threshold`: defines how close we need to get (in terms of molecular Tanimoto similarity to the lead) before considering an analog \"successful\". Set to `1.0` by default (complete Tanimoto similarity).\n",
    "* `scaler_path`: [optional] path to scaler (for the neural net).\n",
    "* `NNmodel_path`: [optional] path to neural net model.\n",
    "\n",
    "About the neural net: If you encounter errors with the neural net model, which is very particular about the number of features, just comment out the code relating to the neural net in the `piggyback_pt2` function where indicated in step 6\n",
    "\n",
    "Output: logs and output csvs are automatically saved to `data/piggybacking_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS ASSUMES THE OEDU FILE FOR THE PROTEIN HAS ALREADY BEEN GENERATED AND STORED IN THE PROPER DIRECTORY\n",
    "\n",
    "def piggyback_pt2(frag_lead_idx, pdb_type, model_idx, weights, k=10, max_iterations=15, threshold=1.0, scaler_path=None, NNmodel_path=None):\n",
    "\n",
    "\n",
    "\n",
    "    ##### step 1: frontmatter #####\n",
    "\n",
    "    frag_smi = fragment_lead_pairs['Fragment'][frag_lead_idx-1]\n",
    "    lead_smi = fragment_lead_pairs['Lead'][frag_lead_idx-1]\n",
    "\n",
    "\n",
    "\n",
    "    ##### step 2: write parameters to log file #####\n",
    "\n",
    "    # Get the current date and time in Pacific Time\n",
    "    pacific_time = pytz.timezone('America/Los_Angeles')\n",
    "    now = datetime.now(pacific_time)\n",
    "    folder_name = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    new_folder_path = f\"data/piggybacking_output/{folder_name}\"\n",
    "\n",
    "    # Create the new directory\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "    # Create and write to log file\n",
    "    log_file_path = f\"{new_folder_path}/log.txt\"\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        log_file.write(f\"frag_lead_idx: {frag_lead_idx} ({frag_smi})\\n\")\n",
    "        row = pdb_names[pdb_names['fragment_index'] == frag_lead_idx]\n",
    "        log_file.write(f\"pdb_type: {pdb_type} ({row[f'{pdb_type}_pdb_code'].values[0]})\\n\")\n",
    "        log_file.write(f\"model_idx: {model_idx} ({models[model_idx]})\\n\")\n",
    "        log_file.write(f\"metric weights: {weights} ({metrics})\\n\")\n",
    "        log_file.write(f\"k: {k}\\nmax_iterations: {max_iterations}\\nthreshold: {threshold}\\n\")\n",
    "        log_file.write(f\"scaler: {scaler_path}\\nNNmodel: {NNmodel_path}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    #######################################\n",
    "    ########## ENTERING THE LOOP ##########\n",
    "    #######################################\n",
    "\n",
    "    # WHILE ITERATIONS IS < MAX ITERATIONS:\n",
    "    #   CREATE AN EMPTY DATAFRAME TO STORE RESULTS\n",
    "    #   FOR EACH INPUT ANALOG IN inputs:\n",
    "    #       RUN THROUGH THE STEPS AND CONCAT RESULTS TO DATA FRAME\n",
    "    #   SAVE THE FULL RESULTS DATA FRAME TO iterationXXXXX CSV\n",
    "    #   IF THERE ARE ANALOGS IN THE RESULTS DATA FRAME THAT HAVE TANI SIM TO LEAD >= THRESHOLD:\n",
    "    #       WRITE THE ROWS TO winner CSV AND EXIT\n",
    "    #   ELSE:\n",
    "    #       CHOOSE TOP k ANALOGS IN TERMS OF FINAL SCORE\n",
    "    #       WRITE THE ROWS TO top_k CSV\n",
    "    #       WRITE THE SMILES COLUMN TO THE inputs ARRAY\n",
    "    #       INCREMENT ITERATION INDEX\n",
    "\n",
    "\n",
    "\n",
    "    curr_iter = 1\n",
    "    input_analogs = [frag_smi]\n",
    "\n",
    "    while curr_iter <= max_iterations:\n",
    "\n",
    "        results = pd.DataFrame()\n",
    "\n",
    "        for input_smiles in input_analogs:\n",
    "\n",
    "\n",
    "\n",
    "            ##### step 3: generate analogs #####\n",
    "\n",
    "            # overwrite mol2mol.smi with the input molecule\n",
    "            with open(\"data/mol2mol.smi\", 'w') as file:\n",
    "                file.write(input_smiles)\n",
    "\n",
    "            # start an empty dataframe to store output from models\n",
    "            smi_df = pd.DataFrame()\n",
    "\n",
    "            # if the model is reinvent:\n",
    "            if model_idx == 0:\n",
    "                # for each of the 6 (functional) priors, run reinvent and append the output to smi_df\n",
    "                for pri in mol2mol_priors:\n",
    "                    toml_filename = \"sampling_\" + pri + \".toml\"\n",
    "                    !reinvent mol2mol_prior_tomls/{toml_filename} --seed 42\n",
    "                    df = pd.read_csv(\"sampling.csv\")\n",
    "                    df['prior'] = pri\n",
    "                    smi_df = pd.concat([smi_df, df], ignore_index=True)\n",
    "            # if the model is crem:\n",
    "            elif model_idx == 1:\n",
    "                db = '../crem_db/crem_db2.5.db'\n",
    "                print(input_smiles)\n",
    "                input_mol = Chem.MolFromSmiles(input_smiles)\n",
    "                out_list = []\n",
    "                grow_list = list(mutate_mol(input_mol, db_name=db,return_mol=False))\n",
    "                for idx,analog in enumerate(grow_list):\n",
    "                    out_list.append([idx,analog,input_smiles])\n",
    "                smi_df = pd.DataFrame(out_list,columns=[\"Idx\",\"SMILES\",\"Input_SMILES\"])\n",
    "                print(len(smi_df))\n",
    "            # if the model is safe:\n",
    "            elif model_idx == 2:\n",
    "                raise ValueError(\"[piggyback_pt2]: oops! safe hasn't been implemented yet\")\n",
    "            # if the model is coati:\n",
    "            elif model_idx == 3:\n",
    "                raise ValueError(\"[piggyback_pt2]: oops! coati hasn't been implemented yet\")\n",
    "            else:\n",
    "                raise ValueError(\"[piggyback_pt2]: model_idx parameter is invalid.\")\n",
    "\n",
    "\n",
    "            ##### step 4: filter odd rings and prep smi_df for evaluation #####\n",
    "\n",
    "            # add a column in the data frame so we know which input molecule it came from\n",
    "            smi_df['predecessor'] = input_smiles # a little redundant, should just be Input_SMILES column\n",
    "\n",
    "            # filter out odd rings\n",
    "            ring_system_lookup = uru.RingSystemLookup.default()\n",
    "            smi_df['ring_systems'] = smi_df.SMILES.apply(ring_system_lookup.process_smiles)\n",
    "            smi_df[['min_ring','min_freq']] = smi_df.ring_systems.apply(uru.get_min_ring_frequency).to_list()\n",
    "            smi_df = smi_df.query('min_freq > 100').copy()\n",
    "            \n",
    "            # remove duplicate values\n",
    "            smi_df.drop_duplicates(inplace=True, ignore_index=True, subset=['SMILES'])\n",
    "\n",
    "            # remove the initial fragment from the generated distribution\n",
    "            if input_smiles in smi_df['SMILES'].values:\n",
    "                smi_df = smi_df[smi_df['SMILES'] != input_smiles]\n",
    "\n",
    "            # add mol id column for identification purposes\n",
    "            smi_df['Name'] = [f\"MOL{i:04d}\" for i in range(0,len(smi_df))]\n",
    "            smi_df[[\"SMILES\",\"Name\"]].to_csv(\"/home/fts_g_ucla_edu/Projects/rips-relay_copy/experiments/placeholder.smi\",sep=\" \",header=None, index=False)\n",
    "\n",
    "            smi_df.round(3)\n",
    "\n",
    "\n",
    "\n",
    "            ##### step 5: compute similarities to lead molecule #####\n",
    "\n",
    "            similarities_to_lead = [tanimoto_similarity(analog, lead_smi, True) for analog in smi_df['SMILES'].values]\n",
    "            smi_df['sim_to_lead'] = similarities_to_lead\n",
    "\n",
    "\n",
    "\n",
    "            ##### step 6: evaluate metrics #####\n",
    "\n",
    "            # add a column to smi_df that contains the final score\n",
    "            smi_df['final_score'] = 0.0\n",
    "\n",
    "\n",
    "\n",
    "            # We assume that we want to compute docking score - comment it out if you don't want it\n",
    "            docked_df = docking_score(path_to_analog_smi=\"placeholder.smi\", output_oeb_path=\"placeholder.oeb\", path_to_oedu=f\"data/docking/pairs/{frag_lead_idx}_{pdb_type}.oedu\", output_sdf_path=\"placeholder.sdf\")\n",
    "            # merge docked_df, which has docking scores, with smi_df by mol ID\n",
    "            smi_df = smi_df.merge(docked_df, left_on='Name', right_on='ID', how='left')\n",
    "            # delete the 'Name' column, as it is now identical to the 'ID' column and redundant\n",
    "            smi_df = smi_df.drop(columns=['Name'])\n",
    "            # convert all docking scores from str to float\n",
    "            smi_df['HYBRID Chemgauss4 score'] = smi_df['HYBRID Chemgauss4 score'].astype('float')\n",
    "\n",
    "\n",
    "            ##### PIFP COUNTS (ASSUMES SDF FROM DOCKING IS IN PLACEHOLDER.SDF) #################\n",
    "            \n",
    "            pifp_sims = pifp_distance_to_lead(path_to_analog_sdf='placeholder.sdf', frag_idx=frag_lead_idx, pdb_type=pdb_type)\n",
    "\n",
    "            # Identify indices with NaNs\n",
    "            nan_indices = smi_df[smi_df.isna().any(axis=1)].index\n",
    "\n",
    "            # Drop rows with NaNs from smi_df\n",
    "            smi_df = smi_df.drop(nan_indices)\n",
    "\n",
    "            # Drop corresponding values from pifp_sims\n",
    "            pifp_sims = np.delete(pifp_sims, nan_indices)\n",
    "\n",
    "            if len(pifp_sims) != len(smi_df):\n",
    "                raise ValueError(\"[piggyback_pt2]: length of pifp_sims does not math length of smi_df\")\n",
    "\n",
    "            ###################################\n",
    "            \n",
    "\n",
    "            # # This section computes the NN model-predicted molecular Tanimoto similarity to the lead\n",
    "            # #   comment it out if necessary\n",
    "            \n",
    "            # if scaler_path != None and NNmodel_path != None:\n",
    "\n",
    "            #     # Add a column with mol object information for each molecule\n",
    "            #     smi_df['ROMol']=[Chem.MolFromSmiles(x) for x in smi_df['SMILES'].values]\n",
    "            #     smi_df['inchi'] = smi_df.ROMol.apply(Chem.MolToInchiKey)\n",
    "            #     smi_df.drop_duplicates(subset=['inchi'])\n",
    "\n",
    "            #     dummy = NNpredict_tani_to_lead(df=smi_df, path_to_scaler=scaler_path, path_to_model=NNmodel_path, curr_iter=curr_iter)\n",
    "                \n",
    "            #     smi_df['NNpredict_tani_to_lead'] = dummy\n",
    "\n",
    "\n",
    "\n",
    "            ##### PIFP COUNTS CONTINUED #################\n",
    "            \n",
    "            smi_df['pifp_sim'] = pifp_sims\n",
    "\n",
    "            ###################################\n",
    "\n",
    "\n",
    "\n",
    "            for w in range(len(weights)): \n",
    "                if weights[w] == 0: # if no weight then we aren't considering it as a contribution so we skip it\n",
    "                    continue\n",
    "                elif w == 0: # tanimoto\n",
    "                    # compute contribution and add to final_score\n",
    "                    smi_df['final_score'] = smi_df['final_score'] + [weighted_score_contribution(weights, w, tani_sim) for tani_sim in smi_df['sim_to_lead']]\n",
    "                elif w == 1: # docking score\n",
    "                    # compute contribution and add to final_score\n",
    "                    smi_df['final_score'] = smi_df['final_score'] + [weighted_score_contribution(weights, w, dock_score) for dock_score in smi_df['HYBRID Chemgauss4 score']]\n",
    "                elif w == 2: #pifp_counts\n",
    "                    # compute contribution and add to final_score\n",
    "                    smi_df['final_score'] = smi_df['final_score'] + [weighted_score_contribution(weights, w, pifp_sim) for pifp_sim in smi_df['pifp_sim']]\n",
    "                elif w == 3: # neural net predicted tani sim to lead\n",
    "                    # compute contribution and add to final_score\n",
    "                    smi_df['final_score'] = smi_df['final_score'] + [weighted_score_contribution(weights, w, NN_score) for NN_score in smi_df['NNpredict_tani_to_lead']]\n",
    "                else:\n",
    "                    raise ValueError(\"[piggyback_pt2]: invalid weight\")\n",
    "            \n",
    "\n",
    "\n",
    "            ##### step 7: concat smi_df to the results dataframe\n",
    "\n",
    "            results = pd.concat([results, smi_df], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        ##### step 8: save full results to csv #####\n",
    "\n",
    "        # remove duplicate values\n",
    "        results.drop_duplicates(inplace=True, ignore_index=True, subset=['SMILES'])\n",
    "        results.to_csv(f\"{new_folder_path}/iter{curr_iter:05d}_full.csv\")\n",
    "\n",
    "\n",
    "\n",
    "        ##### step 9: check if there are analogs in that have tani sim to lead >= threshold #####\n",
    "\n",
    "        successful_rows = results[results['sim_to_lead'] >= threshold]\n",
    "\n",
    "        # check if the number of successful rows is non-zero\n",
    "        if successful_rows.shape[0] > 0:\n",
    "            # write the successful rows to a new CSV file\n",
    "            successful_rows.to_csv(f'{new_folder_path}/iter{curr_iter:05d}_winners.csv', index=False)\n",
    "            # break out of loop\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ##### step 10: choose top k analogs and repeat #####\n",
    "\n",
    "        # Select the top-k rows based on the 'final_score' column\n",
    "        top_k_rows = results.nlargest(k, 'final_score')\n",
    "\n",
    "        # Write the top-k rows to a new CSV file\n",
    "        top_k_rows.to_csv(f'{new_folder_path}/iter{curr_iter:05d}_top-k_rows.csv', index=False)\n",
    "\n",
    "        # Extract the 'SMILES' values from the top-k rows to an array\n",
    "        input_analogs = top_k_rows['SMILES'].values\n",
    "\n",
    "\n",
    "\n",
    "        ##### step 11: increment iteration\n",
    "\n",
    "        curr_iter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results\n",
    "To plot the results, pass in the path to the folder where the piggybacking output data (of the form `data/piggybacking_output/[folder_name]`) is saved, as well as the path to the directory where you want to save the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piggybacking(path_to_folder, save_path):\n",
    "    # Read in the log file\n",
    "    with open(os.path.join(path_to_folder, 'log.txt'), 'r') as file:\n",
    "        log_data = file.read().splitlines()\n",
    "    \n",
    "    # Extract relevant information from the log file\n",
    "    frag_lead_idx = log_data[0].split(': ')[1]\n",
    "    pdb_type = log_data[1].split(': ')[1]\n",
    "    model_idx = log_data[2].split(': ')[1]\n",
    "    metric_weights = log_data[3].split(': ')[1]\n",
    "    k = int(log_data[4].split(': ')[1])\n",
    "    max_iterations = int(log_data[5].split(': ')[1])\n",
    "    threshold = log_data[6].split(': ')[1]\n",
    "\n",
    "    # Initialize arrays to store top-k scores and similarities\n",
    "    scores_array = []\n",
    "    sim_to_lead_array = []\n",
    "\n",
    "    # Loop through each iteration\n",
    "    for i in range(max_iterations + 1):\n",
    "\n",
    "        # skip when i == 0\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        # Construct the filename for top-k rows\n",
    "        filename_top_k = f'iter{str(i).zfill(5)}_top-k_rows.csv'\n",
    "        filepath_top_k = os.path.join(path_to_folder, filename_top_k)\n",
    "        \n",
    "        # Check if the top-k file exists\n",
    "        if os.path.exists(filepath_top_k):\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(filepath_top_k)\n",
    "        else:\n",
    "            # Construct the filename for winners\n",
    "            filename_winners = f'iter{str(i).zfill(5)}_winners.csv'\n",
    "            filepath_winners = os.path.join(path_to_folder, filename_winners)\n",
    "            \n",
    "            # Check if the winners file exists\n",
    "            if os.path.exists(filepath_winners):\n",
    "                # Read the CSV file\n",
    "                df = pd.read_csv(filepath_winners)\n",
    "                print(f\"Threshold met. Ending iterations early at iteration {i}.\")\n",
    "                # Extract the 'final_score' and 'sim_to_lead' columns\n",
    "                scores = df['final_score'].to_numpy()\n",
    "                sim_to_lead = df['sim_to_lead'].to_numpy()\n",
    "                # Store the scores and similarities in the arrays\n",
    "                scores_array.append(scores)\n",
    "                sim_to_lead_array.append(sim_to_lead)\n",
    "                break\n",
    "            else:\n",
    "                print(f\"File {filename_top_k} or {filename_winners} not found. Exiting loop early.\")\n",
    "                break\n",
    "        \n",
    "        # Extract the 'final_score' and 'sim_to_lead' columns\n",
    "        scores = df['final_score'].to_numpy()\n",
    "        sim_to_lead = df['sim_to_lead'].to_numpy()\n",
    "        \n",
    "        # Store the scores and similarities in the arrays\n",
    "        scores_array.append(scores)\n",
    "        sim_to_lead_array.append(sim_to_lead)\n",
    "    \n",
    "    # Convert the arrays to DataFrames for easier plotting\n",
    "    scores_df = pd.DataFrame(scores_array).T\n",
    "    sim_to_lead_df = pd.DataFrame(sim_to_lead_array).T\n",
    "    \n",
    "    # Create the plot for final scores\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.violinplot(data=scores_df, inner=None, color=\"skyblue\")\n",
    "    sns.stripplot(data=scores_df, jitter=True, size=2.5, color=\"blue\", linewidth=0.5)\n",
    "    \n",
    "    # Label the plot\n",
    "    plt.title(f'Frag Lead Index: {frag_lead_idx}\\nPDB Type: {pdb_type}, Model Index: {model_idx}\\nMetric Weights: {metric_weights}\\nTop-{k} Final Scores over {len(scores_array)} Iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Final Scores')\n",
    "    \n",
    "    # Save the final scores plot to the specified path\n",
    "    final_scores_save_path = f\"{save_path}_final_scores_plot.png\"\n",
    "    plt.savefig(final_scores_save_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Create the plot for similarities to lead\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.violinplot(data=sim_to_lead_df, inner=None, color=\"lightgreen\", alpha=0.5)\n",
    "    sns.stripplot(data=sim_to_lead_df, jitter=True, size=2.5, color=\"green\", linewidth=0.5)\n",
    "    \n",
    "    # Label the plot\n",
    "    plt.title(f'Frag Lead Index: {frag_lead_idx}\\nPDB Type: {pdb_type}, Model Index: {model_idx}\\nMetric Weights: {metric_weights}\\nTop-{k} Similarities to Lead over {len(scores_array)} Iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Similarity to Lead')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Save the similarities plot to the specified path\n",
    "    sim_to_lead_save_path = f\"{save_path}_sim_to_lead_plot.png\"\n",
    "    plt.savefig(sim_to_lead_save_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Save the plot to the specified path\n",
    "    plt.savefig(save_path)\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = 'data/goodness_scoring_models/final_scaler.pkl'\n",
    "NNmodel = 'data/goodness_scoring_models/final_goodness_predictor.h5'\n",
    "piggyback_pt2(frag_lead_idx=27, pdb_type='frag', model_idx=0, weights=[0, 0, 1, 0], k=10, max_iterations=15, threshold=1.0, scaler_path=None, NNmodel_path=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
