{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "print('Current conda environment:', os.environ['CONDA_DEFAULT_ENV'])\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"false\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "\n",
    "from crem.crem import grow_mol, mutate_mol\n",
    "crem_db = '../crem_db/crem_db2.5.db'\n",
    "\n",
    "import mols2grid\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdFingerprintGenerator, CanonSmiles, Draw, MolFromSmiles, PandasTools\n",
    "from rdkit.Chem.rdmolops import RDKFingerprint\n",
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem.rdFMCS import FindMCS\n",
    "from rdkit.DataStructs.cDataStructs import BulkTanimotoSimilarity\n",
    "import useful_rdkit_utils as uru\n",
    "\n",
    "import prolif as plf\n",
    "\n",
    "import safe as sf\n",
    "import datamol as dm\n",
    "\n",
    "import mols2grid\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "\n",
    "from coati.generative.coati_purifications import embed_smiles\n",
    "from coati.models.io.coati import load_e3gnn_smiles_clip_e2e\n",
    "from coati.models.simple_coati2.io import load_coati2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = '2zdt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_mol = Chem.MolFromMolFile(f\"data/docking/{pdb}_ligand.sdf\")\n",
    "initial = Chem.MolToSmiles(initial_mol)\n",
    "\n",
    "MolsToGridImage([Chem.MolFromSmiles(initial)], subImgSize=(600, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction fingerprint for reference molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_MOL_FILEPATH = f\"data/docking/{pdb}_ligand.sdf\"\n",
    "PDB_FILEPATH = f\"data/docking/{pdb}.pdb\"\n",
    "\n",
    "fp = plf.Fingerprint()\n",
    "\n",
    "mol = Chem.MolFromPDBFile(PDB_FILEPATH, removeHs=False)\n",
    "prot = plf.Molecule(mol)\n",
    "suppl = plf.sdf_supplier(REF_MOL_FILEPATH)\n",
    "fp.run_from_iterable(suppl, prot, progress=True)\n",
    "df_ifp = fp.to_dataframe()\n",
    "df_ifp.columns = df_ifp.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ifp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifp_similarity(ref_mol_ifp, df_ifp, df):\n",
    "    ## Rename columns\n",
    "    df_ifp.columns = [' '.join(col) if isinstance(col, tuple) else col for col in df_ifp.columns]\n",
    "    ref_mol_ifp.columns = [' '.join(col) if isinstance(col, tuple) else col for col in ref_mol_ifp.columns]\n",
    "    \n",
    "\n",
    "    intersections = []\n",
    "    weighted_intersections = []\n",
    "\n",
    "    #iterate over the rows\n",
    "    for index, row in df_ifp.iterrows():\n",
    "        count=0\n",
    "        weighted_count = 0\n",
    "        #iterate over all columns\n",
    "        for col_name in df_ifp.columns:\n",
    "            if col_name in ref_mol_ifp.columns and df_ifp[col_name][index]==ref_mol_ifp[col_name][0] and 'VdWContact' in col_name:\n",
    "                count += 1\n",
    "                weighted_count += 1\n",
    "            elif col_name in ref_mol_ifp.columns and df_ifp[col_name][index]==ref_mol_ifp[col_name][0] and 'Hydrophobic' in col_name:\n",
    "                count += 1\n",
    "                weighted_count += 2\n",
    "            elif col_name in ref_mol_ifp.columns and df_ifp[col_name][index]==ref_mol_ifp[col_name][0] and 'HBAcceptor' in col_name:\n",
    "                count += 1\n",
    "                weighted_count += 3\n",
    "            elif col_name in ref_mol_ifp.columns and df_ifp[col_name][index]==ref_mol_ifp[col_name][0] and 'Anionic' in col_name or 'Cationic' in col_name:\n",
    "                count += 1\n",
    "                weighted_count += 4\n",
    "        \n",
    "        intersections.append(count)\n",
    "        weighted_intersections.append(weighted_count)\n",
    "                \n",
    "    df['IFP Intersection'] = intersections\n",
    "    df['Weighted IFP Intersection'] = weighted_intersections\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes as input two dataframes with the same number of rows and computes number of IMFs of each molecule wrt protein\n",
    "def compute_features(df, ifp):\n",
    "\n",
    "   # List of new columns to add\n",
    "    new_columns = ['num_interactions', 'weighted_interactions', 'num_VdW', 'num_hydrophobic', 'num_HBAcceptor', 'num_ionic']\n",
    "\n",
    "    # Create a dictionary of new columns with pd.NA values\n",
    "    new_cols_dict = {col: pd.NA for col in new_columns}\n",
    "\n",
    "    # Add multiple empty columns\n",
    "    df = df.assign(**new_cols_dict)\n",
    "   \n",
    "    cols = ifp.columns\n",
    "\n",
    "    data = {'mol_id' : [],\n",
    "            'num_interactions' : [],\n",
    "            'weighted_interactions' : [],\n",
    "            'num_VdW' : [],\n",
    "            'num_hydrophobic' : [],\n",
    "            'num_HBAcceptor' : [],\n",
    "            'num_ionic' : []}\n",
    "    \n",
    "    for index, row in ifp.iterrows():\n",
    "\n",
    "        weighted_interactions = 0\n",
    "        num_VdW = 0\n",
    "        num_hydrophobic = 0\n",
    "        num_HBAcceptor = 0\n",
    "        num_ionic = 0\n",
    "        \n",
    "        # data['mol_id'].append(df.row['ID'][0])\n",
    "        # data['num_interactions'].append(row[:-1].sum())\n",
    "\n",
    "        for value in cols:\n",
    "            \n",
    "            if value[1] == 'VdWContact':\n",
    "                weighted_interactions += 1 * row[value]\n",
    "                num_VdW += 1 * row[value]\n",
    "            elif value[1] == 'Hydrophobic':\n",
    "                weighted_interactions += 2 * row[value]\n",
    "                num_hydrophobic += 1 * row[value]\n",
    "            elif value[1] == 'HBAcceptor':\n",
    "                weighted_interactions += 3 * row[value]\n",
    "                num_HBAcceptor += 1 * row[value]\n",
    "            elif value[1] == 'Anionic' or value[1] == 'Cationic':\n",
    "                weighted_interactions += 4 * row[value]\n",
    "                num_ionic += 1 * row[value]\n",
    "\n",
    "            num_interactions=num_VdW + num_HBAcceptor + num_hydrophobic + num_ionic\n",
    "        df['weighted_interactions'][index]=weighted_interactions\n",
    "        df['num_VdW'][index]=num_VdW\n",
    "        df['num_hydrophobic'][index]=num_hydrophobic\n",
    "        df['num_HBAcceptor'][index]=num_HBAcceptor\n",
    "        df['num_ionic'][index]=num_ionic\n",
    "        df['num_interactions'][index]=num_interactions\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df \n",
    "\n",
    "    ### OLD CODE IN CASE FUNCTION DOESN'T WORK\n",
    "    \n",
    "    # data['weighted_interactions'].append(weighted_interactions)\n",
    "    # data['num_VdW'].append(num_VdW)\n",
    "    # data['num_hydrophobic'].append(num_hydrophobic)\n",
    "    # data['num_HBAcceptor'].append(num_HBAcceptor)\n",
    "    # data['num_ionic'].append(num_ionic) \n",
    "\n",
    "    # features = pd.DataFrame(data)\n",
    "    \n",
    "    # df = df.append(features[['mol_id', 'num_interactions', 'weighted_interactions', 'num_VdW', 'num_hydrophobic', 'num_HBAcceptor', 'num_ionic']], left_on='ID', right_on='mol_id', how='left')\n",
    "\n",
    "    # df = df.drop(['mol_id'], axis=1).sort_values(['Docking score'], ascending=True)\n",
    "\n",
    "    # df.dropna(axis=0, subset=['Docking score'], inplace=True)\n",
    "    # df['num_interactions'].fillna(0, inplace=True)\n",
    "    # df['weighted_interactions'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_fingerprint(ifp):\n",
    "\n",
    "    sns.set(rc = {'figure.figsize':(15,8)})\n",
    "    ax = sns.heatmap(ifp,cmap=sns.cm.rocket_r)\n",
    "    ax.set_ylabel(\"Molecule\")\n",
    "    ax.set_xlabel(\"Protein Interaction\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'reinvent'\n",
    "\n",
    "arg1 = '--model'\n",
    "arg2 = '--sample'\n",
    "arg3 = '--dock'\n",
    "arg4 = '--pdb'\n",
    "\n",
    "args = ['python3', 'generate_analogs.py',\n",
    "        arg1, model,\n",
    "        arg2, '200',\n",
    "        arg3,\n",
    "        arg4, pdb]\n",
    "\n",
    "# Change directory to generate analogs with python script\n",
    "%cd ..\n",
    "\n",
    "subprocess.run(args,\n",
    "               stdout=subprocess.DEVNULL,\n",
    "               stderr=subprocess.STDOUT)\n",
    "        \n",
    "# Change directory back to that of the current notebook\n",
    "%cd experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'reinvent'\n",
    "\n",
    "DF_FILEPATH = f'data/{model}_dataframe.csv'\n",
    "IFP_FILEPATH = f'data/{model}_ifp.csv'\n",
    "\n",
    "df_reinvent = pd.read_csv(DF_FILEPATH, index_col=0)\n",
    "\n",
    "ifp_reinvent = pd.read_csv(IFP_FILEPATH, header=[0, 1], index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute length to check that no molecules are being filtered by metric computation\n",
    "len(df_reinvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of IMFs\n",
    "df_reinvent = compute_features(df_reinvent, ifp_reinvent)\n",
    "# Compare IMFs to initial fragment\n",
    "df_reinvent = ifp_similarity(df_ifp, ifp_reinvent, df_reinvent)\n",
    "\n",
    "df_reinvent.drop(['Input_SMILES', 'Prior', 'Tanimoto'], axis=1, inplace=True)\n",
    "df_reinvent['Model'] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that number of rows matches and visualize data_frame\n",
    "df_reinvent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CReM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'crem'\n",
    "\n",
    "arg1 = '--model'\n",
    "arg2 = '--sample'\n",
    "arg3 = '--dock'\n",
    "arg4 = '--pdb'\n",
    "\n",
    "args = ['python3', 'generate_analogs.py',\n",
    "        arg1, model,\n",
    "        arg2, '200',\n",
    "        arg3,\n",
    "        arg4, pdb]\n",
    "\n",
    "# Change directory to generate analogs with python script\n",
    "%cd ..\n",
    "\n",
    "subprocess.run(args,\n",
    "               stdout=subprocess.DEVNULL,\n",
    "               stderr=subprocess.STDOUT)\n",
    "        \n",
    "# Change directory back to that of the current notebook\n",
    "%cd experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'crem'\n",
    "\n",
    "DF_FILEPATH = f'data/{model}_dataframe.csv'\n",
    "IFP_FILEPATH = f'data/{model}_ifp.csv'\n",
    "\n",
    "df_crem = pd.read_csv(DF_FILEPATH, index_col=0)\n",
    "\n",
    "ifp_crem = pd.read_csv(IFP_FILEPATH, header=[0, 1], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ifp_crem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute length to check that no molecules are being filtered by metric computation\n",
    "len(df_reinvent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of IMFs\n",
    "df_crem = compute_features(df_crem, ifp_crem)\n",
    "len(df_crem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare IMFs to initial fragment\n",
    "df_crem = ifp_similarity(df_ifp, ifp_crem, df_crem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.concat((df_reinvent, df_crem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'coati'\n",
    "\n",
    "arg1 = '--model'\n",
    "arg2 = '--sample'\n",
    "arg3 = '--dock'\n",
    "arg4 = '--pdb'\n",
    "\n",
    "args = ['python3', 'generate_analogs.py',\n",
    "        arg1, model,\n",
    "        arg2, '200',\n",
    "        arg3,\n",
    "        arg4, pdb]\n",
    "\n",
    "# Change directory to generate analogs with python script\n",
    "%cd ..\n",
    "\n",
    "subprocess.run(args,\n",
    "               stdout=subprocess.DEVNULL,\n",
    "               stderr=subprocess.STDOUT)\n",
    "        \n",
    "# Change directory back to that of the current notebook\n",
    "%cd experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'coati'\n",
    "\n",
    "DF_FILEPATH = f'data/{model}_dataframe.csv'\n",
    "IFP_FILEPATH = f'data/{model}_ifp.csv'\n",
    "\n",
    "df_coati = pd.read_csv(DF_FILEPATH, index_col=0)\n",
    "\n",
    "ifp_coati = pd.read_csv(IFP_FILEPATH, header=[0, 1], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifp_coati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coati = compute_features(df_coati, ifp_coati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coati = ifp_similarity(df_ifp, ifp_coati, df_coati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.concat((model_df, df_coati))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'safe'\n",
    "\n",
    "arg1 = '--model'\n",
    "arg2 = '--sample'\n",
    "arg3 = '--dock'\n",
    "arg4 = '--pdb'\n",
    "\n",
    "args = ['python3', 'generate_analogs.py',\n",
    "        arg1, model,\n",
    "        arg2, '200',\n",
    "        arg3,\n",
    "        arg4, pdb]\n",
    "\n",
    "# Change directory to generate analogs with python script\n",
    "%cd ..\n",
    "\n",
    "subprocess.run(args,\n",
    "               stdout=subprocess.DEVNULL,\n",
    "               stderr=subprocess.STDOUT)\n",
    "        \n",
    "# Change directory back to that of the current notebook\n",
    "%cd experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'safe'\n",
    "\n",
    "DF_FILEPATH = f'data/{model}_dataframe.csv'\n",
    "IFP_FILEPATH = f'data/{model}_ifp.csv'\n",
    "\n",
    "df_safe = pd.read_csv(DF_FILEPATH, index_col=0)\n",
    "\n",
    "ifp_safe = pd.read_csv(IFP_FILEPATH, header=[0, 1], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_safe = compute_features(df_safe, ifp_safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_safe = ifp_similarity(df_ifp, ifp_safe, df_safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.concat((model_df, df_safe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = model_df['SMILES'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_df['Model'].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Metrics w/ MolScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molscore import MolScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MolScore(model_name='mol2mol', task_config='molscore/feature_selection.json')\n",
    "scores = ms.score(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once finished\n",
    "metrics = ms.compute_metrics(\n",
    "    endpoints=None, # Optional list: by default will use the running final score/reward value\n",
    "    thresholds=None,  # Optional list: if specified will calculate the yield of molecules above that threshold \n",
    "    # chemistry_filters_basic=False,  # Optional, bool: Additionally re-calculate metrics after filtering out unreasonable chemistry\n",
    "    budget=10000,  # Optional, int: Calculate metrics only with molecules within this budget\n",
    "    n_jobs=1,  # Optional, int: Multiprocessing\n",
    "    benchmark=None,  # Optional, str: Name of benchmark, this may specify additional metrics to compute\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('molscore/2024_07_23_mol2mol_feature_selection/iterations/000001_scores.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['desc_MolecularFormula', 'dice_Cmpd1_Sim', 'tanimoto_Cmpd1_Sim', 'desc_SAscore', 'desc_PenLogP'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['smiles', 'model', 'task', 'step',\n",
    "            'batch_idx', 'absolute_time',\n",
    "            'valid', 'valid_score', 'unique',\n",
    "            'occurrences', 'desc_MolecularFormula',\n",
    "            'dice_Sim', 'dice_Cmpd1_Sim',\n",
    "            'tanimoto_Sim', 'tanimoto_Cmpd1_Sim',\n",
    "            'desc_SAscore', 'desc_PenLogP',\n",
    "            'desc_MolWt', 'desc_NumHAcceptors',\n",
    "            'desc_NumHDonors', 'desc_CLogP',\n",
    "            'desc_TPSA', 'desc_NumRotatableBonds',\n",
    "            'desc_MaxConsecutiveRotatableBonds',\n",
    "            'desc_NumAromaticRings', 'desc_FlourineCount',\n",
    "            'desc_FormalCharge', 'desc_RingCount',\n",
    "            'desc_NumAliphaticRings', 'desc_HeavyAtomCount',\n",
    "            'desc_HeavyAtomMolWt', 'amean', 'filter',\n",
    "            'score_time', 'raw_valid_score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['num_interactions'][:200].nunique(), model_df['num_interactions'][200:400].nunique(), model_df['num_interactions'][400:600].nunique(), model_df['num_interactions'][600:].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_ifp_intersection = model_df['Weighted IFP Intersection'].values\n",
    "X['Weighted IFP Similarity'] = weighted_ifp_intersection / model_df['weighted_interactions'].values\n",
    "\n",
    "X['Docking score'] = model_df['Docking score'].values\n",
    "X['rmsd'] = model_df['rmsd'].values\n",
    "# X['num_interactions'] = model_df['num_interactions'].values\n",
    "# X['weighted_interactions'] = model_df['weighted_interactions'].values\n",
    "X['Interaction Weight Ratio'] = model_df['weighted_interactions'].values / model_df['num_interactions'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X['Docking score'] = model_df['Docking score'].values\n",
    "# X['num_interactions'] = model_df['num_interactions'].values\n",
    "# X['weighted_interactions'] = model_df['weighted_interactions'].values\n",
    "# X['interaction weight ratio'] = model_df['weighted_interactions'].values / model_df['num_interactions'].values\n",
    "# X['num_VdW'] = model_df['num_VdW'].values\n",
    "# X['num_hydophobic'] = model_df['num_hydrophobic'].values\n",
    "# X['num_HBAcceptor'] = model_df['num_HBAcceptor'].values\n",
    "# X['num_ionic'] = model_df['num_ionic'].values\n",
    "# X['CLogP * num_interactions'] = df['desc_CLogP'] * X['num_interactions']\n",
    "# X['CLogP * weighted_interactions'] = df['desc_CLogP'] * X['weighted_interactions']\n",
    "# X['rmsd'] = model_df['rmsd'].values\n",
    "# X['IFP Intersection'] = model_df['IFP Intersection'].values\n",
    "# X['Weighted IFP Intersection'] = model_df['Weighted IFP Intersection'].values\n",
    "# X['IFP Similarity'] = X['IFP Intersection'].values / model_df['num_interactions'].values\n",
    "# X['Weighted IFP Similarity'] = X['Weighted IFP Intersection'].values / model_df['weighted_interactions'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis:\n",
    "\n",
    "* Normalizing columns\n",
    "* Evaluating correlations between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {\n",
    "    'desc_QED' : 'QED',\n",
    "    'desc_Bertz' : 'Synthetic Complexity',\n",
    "    'interaction weight ratio' : 'Avg Interaction Strength',\n",
    "    'Weighted IFP Similarity' : 'Weighted Interaction Similarity',\n",
    "    'rmsd' : 'RMSD',\n",
    "    'RAScore_pred_proba' : 'Synthetic Accessibility',\n",
    "    'desc_NumHeteroatoms' : '# Heteroatoms'\n",
    "}\n",
    "\n",
    "X.rename(columns=column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:3].plot(kind='bar', legend=False, logy=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = X.copy()\n",
    "\n",
    "# Normalizing each column using min-max scaler\n",
    "for column in X.columns:\n",
    "   \n",
    "   X_normalized[column] = (X_normalized[column] - X_normalized[column].min()) / (X_normalized[column].max() - X_normalized[column].min())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized[:3].plot(kind='bar', legend=False, logy=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "\n",
    "ord = enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Model'] = ord.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr().style.background_gradient(cmap='coolwarm', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = X.iloc[:15].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(X.corr(method='pearson'), annot=True, fmt='.3f', \n",
    "            cmap=plt.get_cmap('coolwarm'), cbar=True, ax=ax)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=\"horizontal\")\n",
    "plt.xticks(rotation=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=250,\n",
    "                            class_weight='balanced',\n",
    "                            random_state=1)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_pred, y_test, average='micro')\n",
    "\n",
    "print(f'Average precision: {precision:.3f}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = rf.feature_importances_\n",
    "vars = X_normalized.columns\n",
    "\n",
    "d = {'Features': vars, 'Weights': weights}\n",
    "\n",
    "rf_features = pd.DataFrame(data=d).sort_values(['Weights'], ascending=False, ignore_index=True)\n",
    "\n",
    "rf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.barplot(x = 'Features',\n",
    "\t\t\ty = 'Weights',\n",
    "\t\t\tdata = rf_features.loc[:15],\n",
    "            palette='colorblind',\n",
    "            ax=ax)\n",
    "\n",
    "# plt.title('Ranking of Random Forest Features')\n",
    "ax.set_xlabel('Features', fontsize=20)\n",
    "ax.set_ylabel('Feature Importance', labelpad=25, fontsize=20)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Model Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['SMILES'] = df['smiles']\n",
    "X['Tanimoto'] = df['tanimoto_Sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('data/features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['Weighted Interaction Similarity'] = X['Weighted Interaction Similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(model_df[['SMILES', 'Model', 'Docking score', 'num_interactions', 'weighted_interactions', 'num_VdW', 'num_hydrophobic', 'num_HBAcceptor', 'num_ionic', 'rmsd', 'Weighted Interaction Similarity']], left_on='smiles', right_on='SMILES', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['SMILES'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "params = {'vert' : 0}\n",
    "\n",
    "df.boxplot(column=['Docking score'], by='Model', ax=ax, **params)\n",
    "\n",
    "ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FacetGrid with KDE plots\n",
    "g = sns.FacetGrid(df, hue=\"Model\", height=5, aspect=1.5)\n",
    "g.map(sns.kdeplot, \"Docking score\", shade=True).add_legend()\n",
    "\n",
    "# Add title and labels\n",
    "g.fig.suptitle('Distributions of Docking Score by Model')\n",
    "g.set_axis_labels('Docking Score', 'Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FacetGrid with KDE plots\n",
    "g = sns.FacetGrid(df, hue=\"Model\", height=5, aspect=1.5)\n",
    "g.map(sns.kdeplot, \"num_interactions\", shade=True).add_legend()\n",
    "\n",
    "# Add title and labels\n",
    "g.fig.suptitle('Distributions of Docking Score by Model')\n",
    "g.set_axis_labels('Docking Score', 'Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'num_interactions'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x=var, hue='Model', multiple='dodge', palette='colorblind', bins=3, binwidth=.4,)\n",
    "\n",
    "plt.xlabel('Number of interactions')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Number of Protein Interactions by Model')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FacetGrid with KDE plots\n",
    "g = sns.FacetGrid(df, hue=\"Model\", height=5, aspect=1.5)\n",
    "g.map(sns.kdeplot, \"weighted_interactions\", shade=True).add_legend()\n",
    "\n",
    "# Add title and labels\n",
    "g.fig.suptitle('Distributions of Docking Score by Model', y=1.02)\n",
    "g.set_axis_labels('Docking Score', 'Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'weighted_interactions'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x=var, hue='Model', multiple='dodge', palette='colorblind', bins=3, binwidth=.4,)\n",
    "\n",
    "plt.xlabel('Number of interactions')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Number of Protein Interactions by Model')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FacetGrid with KDE plots\n",
    "g = sns.FacetGrid(df, hue=\"Model\", height=5, aspect=1.5)\n",
    "g.map(sns.kdeplot, \"Weighted IFP Similarity\", shade=True).add_legend()\n",
    "\n",
    "# Add title and labels\n",
    "g.fig.suptitle('Kernel Density Plot of Weighted IFP Similarity by Model', y=1.02)\n",
    "g.set_axis_labels('Weighted Interaction Similarity', 'Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "params = {'vert' : 0,\n",
    "          'patch_artist' : True}\n",
    "\n",
    "df.boxplot(column=['rmsd'], by='Model', ax=ax, **params)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.axvline(x=2, ls='dashed', c='green');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FacetGrid with KDE plots\n",
    "g = sns.FacetGrid(df, hue=\"Model\", height=5, aspect=1.5)\n",
    "g.map(sns.kdeplot, \"rmsd\", shade=True).add_legend()\n",
    "plt.axvline(x=2, ls='dashed', c='green')\n",
    "\n",
    "# Add title and labels\n",
    "g.fig.suptitle('Kernel Density Plot of RMSD', y=1.05)\n",
    "g.set_axis_labels('RMSD', 'Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "params = {'vert' : 0}\n",
    "\n",
    "df.boxplot(column=['tanimoto_Sim'], by='Model', ax=ax, **params)\n",
    "\n",
    "ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FacetGrid with KDE plots\n",
    "g = sns.FacetGrid(df, hue=\"Model\", height=5, aspect=1.5)\n",
    "g.map(sns.kdeplot, \"tanimoto_Sim\", shade=True).add_legend()\n",
    "\n",
    "# Add title and labels\n",
    "g.fig.suptitle('Kernel Density Plot of Tanimoto Similarity', y=1.05)\n",
    "g.set_axis_labels('Tanimoto Similarity', 'Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "params = {'vert' : 0,\n",
    "          'patch_artist' : True}\n",
    "\n",
    "df.boxplot(column=['desc_Bertz'], by='Model', ax=ax, **params)\n",
    "\n",
    "ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "params = {'vert' : 0,\n",
    "          'patch_artist' : True}\n",
    "\n",
    "df.boxplot(column=['desc_QED'], by='Model', ax=ax, **params)\n",
    "\n",
    "ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'num_ionic'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x=var, hue='Model', multiple='dodge', palette='colorblind', bins=3, binwidth=.4,)\n",
    "\n",
    "plt.xlabel('Number of ionic bonds')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Number of Ionic Bonds by Model')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing clusters w/ PCA and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3, random_state=0)\n",
    "pca_fps = pca.fit_transform(X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1, var2, var3 = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1, var2, var3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['PC1'], model_df['PC2'], model_df['PC3'] = pca_fps.T[0], pca_fps.T[1], pca_fps.T[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = model_df.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.pairplot(model_df,\n",
    "                 hue='Model',\n",
    "                 vars=['PC1', 'PC2'],\n",
    "                 palette='colorblind',\n",
    "                 aspect=2,\n",
    "                 plot_kws=dict(s=10))\n",
    "\n",
    "f.fig.suptitle(f'Pairwise Principle Component Plots, variance explained: {var1 + var2:.2f}', fontsize=18, y=1.04);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 50\n",
    "\n",
    "pca_model = PCA(n_components=3, random_state=0)\n",
    "tsne_model = TSNE(n_components=2, random_state=0, perplexity=p, n_iter=5000)\n",
    "tsne_fps = tsne_model.fit_transform(pca_model.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['TSNE1'], model_df['TSNE2'] = tsne_fps.T[0], tsne_fps.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.pairplot(model_df,\n",
    "                 hue='Model',\n",
    "                 vars=['TSNE1', 'TSNE2'],\n",
    "                 palette='colorblind',\n",
    "                 aspect=2,\n",
    "                 plot_kws=dict(s=10))\n",
    "\n",
    "title = f'Pairwise t-SNE plot w/ perplexity $p={p}$'\n",
    "\n",
    "f.fig.suptitle(title, fontsize=18, y=1.04);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinvent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
