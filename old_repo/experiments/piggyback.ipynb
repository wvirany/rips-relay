{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piggybacking Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "print('Current conda environment:', os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from crem.crem import grow_mol, mutate_mol\n",
    "crem_db = '../crem_db/crem_db2.5.db'\n",
    "\n",
    "import mols2grid\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import DataStructs\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc = {'figure.figsize':(15,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_lead_pairs = pd.read_csv('data/fragment_lead_pairs.csv')\n",
    "\n",
    "fragment_lead_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto_similarity(smi_1, smi_2, use_counts=True):\n",
    "    fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048,countSimulation=True)\n",
    "    mol_1 = Chem.MolFromSmiles(smi_1)\n",
    "    mol_2 = Chem.MolFromSmiles(smi_2)\n",
    "    if use_counts:\n",
    "        fp_1 = rdFingerprintGenerator.GetCountFPs([mol_1])[0]\n",
    "        fp_2 = rdFingerprintGenerator.GetCountFPs([mol_2])[0]\n",
    "    else:\n",
    "        fp_1 = rdFingerprintGenerator.GetFPs([mol_1])[0]\n",
    "        fp_2 = rdFingerprintGenerator.GetFPs([mol_2])[0]\n",
    "    return DataStructs.TanimotoSimilarity(fp_1, fp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piggyback(initial, lead, mol_list, dataframes, model='reinvent'):\n",
    "\n",
    "    initial_mol = Chem.MolFromSmiles(initial)\n",
    "    results = {}    # Temporary dict to store results per-run\n",
    "\n",
    "    if model == 'reinvent': # Generate analogs w/ REINVENT\n",
    "\n",
    "        # Change directory to run python script\n",
    "        %cd ..\n",
    "\n",
    "        arg1 = f'--input_frag'\n",
    "        subprocess.run(['python3', 'generate_analogs.py', arg1, initial],\n",
    "                    stdout=subprocess.DEVNULL,\n",
    "                    stderr=subprocess.STDOUT)\n",
    "        \n",
    "        # Change directory back to that of the current notebook\n",
    "        %cd experiments\n",
    "        \n",
    "        # Read dataframe\n",
    "        df = pd.read_csv('data/dataframe.csv')\n",
    "        df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    \n",
    "    elif model == 'crem':   # Generate analogs w/ CReM\n",
    "        \n",
    "        out_list = []\n",
    "        mutate_list = list(mutate_mol(initial_mol, db_name=crem_db, return_mol=False))\n",
    "\n",
    "        for idx, analog in enumerate(mutate_list):\n",
    "            out_list.append([analog, initial])\n",
    "\n",
    "        df = pd.DataFrame(out_list, columns=[\"SMILES\",\"Input_SMILES\"])\n",
    "\n",
    "    else:   # Raise an error if an invalid model is entered\n",
    "        raise Exception('Invalid Model')\n",
    "    \n",
    "    # Remove duplicate values\n",
    "    df.drop_duplicates(inplace=True, ignore_index=True, subset=['SMILES'])\n",
    "    \n",
    "    # Remove the initial fragment from the generated distribution\n",
    "    if initial in df['SMILES'].values:\n",
    "\n",
    "        index = df.loc[df['Tanimoto'] == 1].index[0]\n",
    "        df.drop(index)\n",
    "\n",
    "    df.round(3)\n",
    "\n",
    "    dataframes.append(df)\n",
    "\n",
    "    # Compute similarities to lead molecule\n",
    "    similarities_to_lead = [tanimoto_similarity(analog, lead, True) for analog in df['SMILES'].values]\n",
    "    df['sim_to_lead'] = similarities_to_lead\n",
    "    df.sort_values('sim_to_lead', ascending=False, inplace=True)\n",
    "\n",
    "    # Calculate mean and max Tanimoto similarities\n",
    "    results['mean'], results['max'], results['num_analogs'] = [df['sim_to_lead'].mean()], [df['sim_to_lead'].max()], len(df)\n",
    "    \n",
    "\n",
    "    if len(df) > 0:\n",
    "        # Find SMILES string corresponding to best value\n",
    "        best = df['SMILES'].values[0]\n",
    "        \n",
    "        # Add best to list of piggybacked molecules\n",
    "        mol_list.append(Chem.MolFromSmiles(best))\n",
    "    else:\n",
    "        best = None\n",
    "\n",
    "    return best, mol_list, results, dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(initial, lead, model='reinvent', max_iters=10):\n",
    "\n",
    "    dataframes = []\n",
    "    best = initial\n",
    "    best_tanimoto = tanimoto_similarity(initial, lead)\n",
    "    n_iters = 0\n",
    "    mol_list = [Chem.MolFromSmiles(initial)]\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    while best_tanimoto < 1.0 and n_iters < max_iters:\n",
    "\n",
    "        n_iters += 1\n",
    "\n",
    "        print(f'\\n ===   Iteration: {n_iters}   === \\n')\n",
    "\n",
    "        best, mol_list, results, dataframes = piggyback(best, lead, mol_list, dataframes, model)\n",
    "\n",
    "        if best == None:\n",
    "            print('Empty Dataframe')\n",
    "            break\n",
    "\n",
    "        temp_df = pd.DataFrame(data=results)\n",
    "\n",
    "        results_df = pd.concat((results_df, temp_df))\n",
    "\n",
    "        if best_tanimoto == results['max'][0]:\n",
    "            print(f'GOT STUCK: {best_tanimoto}')\n",
    "            break\n",
    "        else:\n",
    "            best_tanimoto = results['max'][0]\n",
    "        \n",
    "        print(f'\\n ===   CURRENT BEST: {best_tanimoto}   === \\n')\n",
    "\n",
    "    mol_list.append(Chem.MolFromSmiles(lead))\n",
    "\n",
    "    return results_df, mol_list, dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring representative fragment-lead pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "i = 0\n",
    "\n",
    "initial, lead = fragment_lead_pairs['Fragment'][i], fragment_lead_pairs['Lead'][i]\n",
    "            \n",
    "results_df, mol_list, dataframes = run_experiment(initial, lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols2grid.display(mol_list, size=(300, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(dataframes):\n",
    "\n",
    "    max = results_df['max'].values[i]\n",
    "    mean = results_df['mean'].values[i]\n",
    "\n",
    "    print(f' === Distribution: {i} === \\n')\n",
    "    print(f'Best similarity to lead: {max}')\n",
    "    print(f'Average similarity to lead: {mean}')\n",
    "    print(f'Size of distribution: {len(df)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distributions = len(dataframes)\n",
    "\n",
    "for i in range(num_distributions - 1):\n",
    "\n",
    "    df1, df2 = dataframes[i], dataframes[i+1]\n",
    "\n",
    "    int_df = pd.merge(df1, df2, how='inner', on=['SMILES'])\n",
    "    union_df = pd.merge(df1, df2, how='outer', on=['SMILES'])\n",
    "\n",
    "    int_size = len(int_df)\n",
    "    union_size = len(union_df)\n",
    "\n",
    "    sim_score = int_size / union_size\n",
    "\n",
    "    print(f'Size of intersection between distribution {i} and {i+1}: {int_size}')\n",
    "    print(f'Similarity score: {sim_score}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing each distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(dataframes):\n",
    "    df['Distribution'] = i\n",
    "\n",
    "df = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = df['SMILES'].values\n",
    "mols = [Chem.MolFromSmiles(smile) for smile in smiles]\n",
    "\n",
    "fpgen = AllChem.GetMorganGenerator()\n",
    "fingerprints = [fpgen.GetFingerprint(mol) for mol in mols]\n",
    "\n",
    "X = fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3, random_state=0)\n",
    "pca_fps = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PC1'], df['PC2'], df['PC3'] = pca_fps.T[0], pca_fps.T[1], pca_fps.T[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.pairplot(plot_df,\n",
    "                 hue='Distribution',\n",
    "                 vars=['PC1', 'PC2', 'PC3'],\n",
    "                 palette='tab10',\n",
    "                 aspect=2,\n",
    "                 plot_kws=dict(s=10))\n",
    "\n",
    "f.fig.suptitle('Pairwise Principle Component Plots', fontsize=18, y=1.04);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinvent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
